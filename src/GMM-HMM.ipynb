{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from hmmlearn import hmm\n",
    "import os\n",
    "import librosa\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from common import *\n",
    "from IPython import display\n",
    "LABELS.remove(\"sil\")\n",
    "STATES = STATES[:-1]\n",
    "\n",
    "os.chdir('..')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_mfcc(file: str):\n",
    "    y, sr = librosa.load(file)\n",
    "    mfcc = librosa.feature.mfcc(y=y, sr=sr, n_mfcc=13)\n",
    "    delta = librosa.feature.delta(mfcc)\n",
    "    delta2 = librosa.feature.delta(mfcc, order=2)\n",
    "    return np.vstack((mfcc, delta, delta2)).T"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = {}\n",
    "idx_labels = {}\n",
    "\n",
    "# mfcc in data, index of label in idx_labels\n",
    "\n",
    "for label in LABELS:\n",
    "    if label == \"sil\":\n",
    "        continue\n",
    "    files = os.listdir(f\"audio_per_labels/audio/{label}\")\n",
    "    _data = [get_mfcc(f\"audio_per_labels/audio/{label}/{file}\") for file in files]\n",
    "    data[label] = _data\n",
    "    idx_labels[label] = [LABELS.index(label)] * len(_data)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "X = {'train': {}, 'test': {}}\n",
    "y = {'train': {}, 'test': {}}\n",
    "\n",
    "for label in LABELS:\n",
    "    x_train, x_test, y_train, y_test = train_test_split(data[label], idx_labels[label], test_size=0.2)\n",
    "\n",
    "    X['train'][label] = x_train\n",
    "    X['test'][label] = x_test\n",
    "    y['train'][label] = y_train\n",
    "    y['test'][label] = y_test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "len: 101 / 26\n",
      "xuong: 96 / 24\n",
      "trai: 100 / 25\n",
      "phai: 91 / 23\n",
      "nhay: 112 / 28\n",
      "ban: 93 / 24\n",
      "A: 97 / 25\n",
      "B: 107 / 27\n",
      "(13, 39)\n"
     ]
    }
   ],
   "source": [
    "for label in LABELS:\n",
    "    print(f\"{label}: {len(X['train'][label])} / {len(X['test'][label])}\")\n",
    "\n",
    "print(X['train']['A'][0].shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "models = {}\n",
    "\n",
    "for idx, label in enumerate(LABELS):\n",
    "    models[label] = hmm.GMMHMM(n_components=STATES[idx], covariance_type=\"diag\", n_iter=300)\n",
    "    models[label].fit(X=np.vstack(X['train'][label]), lengths=[x.shape[0] for x in X['train'][label]])  \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       1.00      0.88      0.94        26\n",
      "           1       1.00      1.00      1.00        24\n",
      "           2       0.93      1.00      0.96        25\n",
      "           3       1.00      0.96      0.98        23\n",
      "           4       0.96      0.93      0.95        28\n",
      "           5       0.96      0.92      0.94        24\n",
      "           6       0.96      1.00      0.98        25\n",
      "           7       0.90      1.00      0.95        27\n",
      "\n",
      "    accuracy                           0.96       202\n",
      "   macro avg       0.96      0.96      0.96       202\n",
      "weighted avg       0.96      0.96      0.96       202\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from sklearn.metrics import classification_report\n",
    "y_true = []\n",
    "y_preds = []\n",
    "\n",
    "for label in LABELS:\n",
    "    for mfcc, target in zip(X['test'][label], y['test'][label]):\n",
    "        scores = [models[label].score(mfcc) for label in LABELS]\n",
    "        preds = np.argmax(scores)\n",
    "        y_true.append(target)\n",
    "        y_preds.append(preds)\n",
    "\n",
    "report = classification_report(y_true, y_preds)\n",
    "print(report)"
   ]
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "98c875e246d3f0bcfe1f93bff34b62c3e293936ea0df7b23d069516d651a68f8"
  },
  "kernelspec": {
   "display_name": "Python 3.10.4 ('SR-Homework2': venv)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.4"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
